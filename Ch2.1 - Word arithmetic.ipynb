{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word arithmetic\n",
    "In this practice notebook, we'll explore how you can calculate with word embeddings.\n",
    "\n",
    "If needed (e.g. on Google Colab), first install the necessary packages and download the correct model by uncommenting the following two cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordfreq spacy-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8vW9svTE289D"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from wordfreq import zipf_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors are only available in larger models, so let's load that first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mWDrpxDk2_r2"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "s = \"It's not about the money (only $20.15), it's about sending a message :). ðŸš€ðŸ’ŽðŸ™Œ\"\n",
    "doc = nlp(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "money"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = doc[5]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.8580e-02,  4.6470e-01,  1.3214e-01,  1.8599e-01, -3.7015e-02,\n",
       "        3.2988e-01,  1.7865e-01, -2.5977e-01, -2.6022e-01,  2.5728e+00,\n",
       "       -2.5867e-01, -6.6095e-01,  8.1984e-02,  1.0321e-02, -1.2223e-01,\n",
       "        9.4609e-03, -8.8657e-02,  5.8367e-01, -1.7465e-02, -3.5569e-01,\n",
       "       -1.0182e-01,  6.1941e-02, -1.4267e-01, -4.0544e-01,  2.9834e-01,\n",
       "        1.0003e-01,  3.5899e-02,  2.2920e-01,  3.0278e-01, -1.8259e-01,\n",
       "       -1.1042e-03,  2.5792e-01, -5.4132e-02,  1.5748e-01,  6.1311e-02,\n",
       "       -3.0055e-01,  3.3732e-01,  4.0023e-01,  4.2472e-02, -3.0014e-01,\n",
       "        6.2963e-02,  7.2134e-02,  6.0897e-02, -6.2527e-02,  2.7505e-01,\n",
       "       -1.3527e-01, -2.1710e-01,  1.9315e-02,  3.8683e-02, -1.2361e-01,\n",
       "       -7.7210e-02, -1.1320e-01, -9.3050e-02,  3.5217e-01,  1.9300e-01,\n",
       "        4.8418e-02, -2.0489e-01,  9.6088e-02,  7.7817e-02, -3.7924e-01,\n",
       "        1.1290e-01, -1.8285e-01, -5.6815e-02,  3.7091e-01,  3.2133e-01,\n",
       "       -1.6343e-01, -3.0290e-01,  2.0258e-01, -1.9113e-01, -4.1821e-02,\n",
       "        9.6427e-02,  2.8788e-01,  2.1868e-01,  1.1835e-01, -5.8606e-01,\n",
       "        8.4765e-02,  4.0064e-02,  3.8934e-02, -4.1745e-04,  1.2880e-01,\n",
       "        3.2659e-02,  2.7487e-01,  3.2105e-01,  1.1337e-01,  2.3331e-01,\n",
       "       -2.0270e-01, -7.5498e-01, -2.1488e-01,  1.1081e-01, -1.2337e-01,\n",
       "       -6.8252e-01,  4.6154e-01, -1.8431e-01, -4.0732e-01,  2.9356e-01,\n",
       "        1.8444e-01,  4.6945e-02, -1.6625e-01,  2.8425e-01,  9.8857e-02,\n",
       "        1.4131e-01,  9.9858e-03, -7.7743e-02, -4.1674e-02, -1.6059e-01,\n",
       "        6.6496e-01,  3.8880e-01,  6.1784e-02, -2.3028e-01, -8.5093e-02,\n",
       "        1.5053e-01,  5.0199e-01, -6.0354e-02,  7.8031e-03, -1.0188e-01,\n",
       "        1.8607e-01,  1.1777e-01, -1.5382e-01,  1.7520e-01,  3.4421e-01,\n",
       "        6.1868e-02, -5.8456e-02,  1.9939e-01,  2.4807e-01, -1.2043e-01,\n",
       "        2.4495e-01, -2.2755e-01, -4.4586e-02, -7.8157e-02, -3.7290e-01,\n",
       "       -2.6008e-01, -3.1267e-01,  4.6500e-01, -1.4188e-01, -9.2598e-02,\n",
       "        6.7002e-02,  2.2380e-01,  5.0371e-01, -4.1528e-01, -3.5387e-02,\n",
       "       -1.1150e+00,  1.0314e-01,  1.0069e-01,  2.6980e-01, -8.6038e-02,\n",
       "       -1.8304e-01, -1.1100e-01,  3.3949e-01, -1.5439e-01, -6.0346e-02,\n",
       "       -7.6030e-02,  3.6591e-01,  7.6120e-02,  1.4184e-01, -6.6350e-02,\n",
       "       -4.2175e-01, -6.8802e-01,  1.6540e-01, -1.5966e-01, -8.2361e-02,\n",
       "       -3.7665e-01,  1.5192e-01, -1.5739e-01,  7.5572e-02, -9.3941e-02,\n",
       "       -5.3344e-01,  2.5038e-01, -1.7772e-01,  5.6826e-01,  2.3024e-02,\n",
       "       -1.3049e-01, -2.3437e-01, -1.4206e-01, -3.6676e-01, -8.7881e-01,\n",
       "       -1.7991e-01,  6.1699e-01, -5.4129e-02, -4.1839e-02,  4.4565e-01,\n",
       "        7.1349e-02,  1.1386e-02, -1.3037e-01, -3.6068e-02, -9.1853e-02,\n",
       "        2.8994e-01,  3.5194e-01,  1.8153e-02, -2.7042e-01, -3.8262e-01,\n",
       "       -4.1694e-01,  8.8887e-02, -3.8843e-01,  9.1897e-02, -1.6549e-01,\n",
       "        1.3396e-01,  1.2725e-01, -3.0501e-01, -8.9378e-02,  2.4039e-01,\n",
       "       -2.9861e-01, -1.0235e-02,  1.1287e-02,  3.9926e-02,  2.2518e-01,\n",
       "       -1.4535e-02, -1.4116e-01, -1.0092e-01, -1.1393e-01, -4.2583e-01,\n",
       "       -1.5182e-01, -4.1830e-01,  9.5807e-02, -4.1133e-01,  3.0601e-01,\n",
       "        2.5951e-01, -1.1851e-01, -6.3935e-02, -6.8160e-01, -3.2533e-01,\n",
       "       -3.1124e-01,  2.6500e-01, -1.7040e-01, -1.3757e-01, -1.3244e-01,\n",
       "       -7.3419e-02, -7.9024e-02,  7.2515e-02,  6.9922e-02,  2.9591e-01,\n",
       "       -3.2007e-01,  9.1738e-02, -1.8087e-01,  7.1566e-02, -2.0362e-01,\n",
       "       -1.9141e-01, -8.5196e-02, -4.7908e-01,  6.4813e-02, -2.1795e-01,\n",
       "       -9.4415e-02,  5.3729e-01,  8.3135e-03,  2.4061e-01,  4.5261e-02,\n",
       "       -8.1265e-02, -3.8758e-02,  1.1975e-01, -1.0087e-01, -2.2780e-01,\n",
       "       -6.6300e-02, -6.9051e-02,  2.6849e-01, -1.6083e-01, -1.6018e-01,\n",
       "        2.6183e-01, -5.4176e-01,  3.1235e-02,  1.4158e-01,  1.4993e-01,\n",
       "       -3.1776e-01,  2.0251e-01, -5.0593e-02,  1.4712e-01, -1.6181e-02,\n",
       "        6.5722e-02, -7.6293e-02, -3.6481e-01,  4.4407e-01, -6.6691e-02,\n",
       "        4.6171e-01,  3.9474e-02, -4.4825e-01, -4.0562e-01,  1.2919e-01,\n",
       "        3.5828e-02, -2.9879e-02,  2.5034e-02,  2.5427e-01,  1.7060e-01,\n",
       "        2.3547e-01,  4.6183e-01, -7.1739e-02,  1.1056e-01, -5.0868e-01,\n",
       "        1.5953e-01, -1.9542e-01,  2.2428e-01, -9.8993e-02, -3.0309e-01,\n",
       "        1.3260e-01,  1.5582e-01,  2.1946e-01, -1.5946e-02,  1.6345e-01,\n",
       "       -2.6763e-01,  4.2565e-02, -9.4786e-02,  2.8878e-01, -2.5244e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = doc[1]\n",
    "token.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.vector.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_id(word: str):\n",
    "    return nlp.vocab.strings[word]\n",
    "\n",
    "def get_vector(word: str):\n",
    "    return nlp.vocab.vectors[get_vocab_id(word)]\n",
    "\n",
    "def get_token(word: str):\n",
    "    return nlp(word)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4066064953804016"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_token(\"woman\").similarity(get_token(\"queen\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat cat 1.0\n",
      "cat lion 0.5265437364578247\n",
      "cat pet 0.7505456209182739\n",
      "lion cat 0.5265437364578247\n",
      "lion lion 1.0\n",
      "lion pet 0.39923766255378723\n",
      "pet cat 0.7505456209182739\n",
      "pet lion 0.39923766255378723\n",
      "pet pet 1.0\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'cat lion pet')\n",
    "\n",
    "for t1 in tokens:\n",
    "    for t2 in tokens:\n",
    "        print(t1.text,t2.text,t1.similarity(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "castle, castle, 1.000\n",
      "castle, king, 0.437\n",
      "castle, student, 0.087\n",
      "castle, error, 0.027\n",
      "king, castle, 0.437\n",
      "king, king, 1.000\n",
      "king, student, 0.119\n",
      "king, error, 0.110\n",
      "student, castle, 0.087\n",
      "student, king, 0.119\n",
      "student, student, 1.000\n",
      "student, error, 0.162\n",
      "error, castle, 0.027\n",
      "error, king, 0.110\n",
      "error, student, 0.162\n",
      "error, error, 1.000\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'castle king student error')\n",
    "\n",
    "for t1 in tokens:\n",
    "    for t2 in tokens:\n",
    "        print(f\"{t1.text}, {t2.text}, {t1.similarity(t2):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find most similar words to a given vector\n",
    "Documentation https://spacy.io/api/vectors#most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar(vec: np.ndarray, include_rare = False):\n",
    "    # vec = vector(word)\n",
    "\n",
    "    vocab_ids = nlp.vocab.vectors.most_similar(np.asarray([vec]), n=100)\n",
    "    words =  [nlp.vocab.strings[w] for w in vocab_ids[0][0]]\n",
    "    if include_rare:\n",
    "        return [w.lower() for w in words if get_token(w).is_alpha][0:20]\n",
    "    else:\n",
    "        return [w.lower() for w in words if get_token(w).is_alpha & (zipf_frequency(w, \"en\", wordlist='small', minimum=1)> 3)][0:20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doctor',\n",
       " 'physician',\n",
       " 'doctors',\n",
       " 'pharmacist',\n",
       " 'surgeon',\n",
       " 'medical',\n",
       " 'nurse',\n",
       " 'medicine',\n",
       " 'medication',\n",
       " 'patient',\n",
       " 'pediatrician',\n",
       " 'psychiatrist',\n",
       " 'clinic',\n",
       " 'dentist',\n",
       " 'medications',\n",
       " 'meds',\n",
       " 'hospital',\n",
       " 'dermatologist',\n",
       " 'neurologist',\n",
       " 'surgery']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"doctor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['queen',\n",
       " 'king',\n",
       " 'princess',\n",
       " 'prince',\n",
       " 'kings',\n",
       " 'girl',\n",
       " 'queens',\n",
       " 'royal',\n",
       " 'princesses',\n",
       " 'throne',\n",
       " 'kingdom',\n",
       " 'princes',\n",
       " 'girls',\n",
       " 'duke',\n",
       " 'empress',\n",
       " 'barbie',\n",
       " 'angel',\n",
       " 'fairy',\n",
       " 'sister',\n",
       " 'daughter']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"king\") - get_vector(\"man\") + get_vector(\"girl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doctor',\n",
       " 'nurse',\n",
       " 'doctors',\n",
       " 'physician',\n",
       " 'pregnant',\n",
       " 'woman',\n",
       " 'pharmacist',\n",
       " 'midwife',\n",
       " 'medical',\n",
       " 'pediatrician',\n",
       " 'patient',\n",
       " 'pregnancy',\n",
       " 'surgeon',\n",
       " 'clinic',\n",
       " 'medication',\n",
       " 'medicine',\n",
       " 'hospital',\n",
       " 'nurses',\n",
       " 'psychiatrist',\n",
       " 'therapist']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"doctor\") - get_vector(\"man\") + get_vector(\"woman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['student',\n",
       " 'school',\n",
       " 'castle',\n",
       " 'university',\n",
       " 'students',\n",
       " 'campus',\n",
       " 'college',\n",
       " 'graduate',\n",
       " 'teacher',\n",
       " 'undergraduate',\n",
       " 'classroom',\n",
       " 'professor',\n",
       " 'tutor',\n",
       " 'faculty',\n",
       " 'elementary',\n",
       " 'dormitory',\n",
       " 'schools',\n",
       " 'teaching',\n",
       " 'classmate',\n",
       " 'academic']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"castle\") - get_vector(\"royalty\") + get_vector(\"student\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tokyo'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_similar(get_vector(\"Berlin\") - get_vector(\"Germany\") + get_vector(\"Japan\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_most_similar(get_vector(\"bigger\") - get_vector(\"big\") + get_vector(\"cold\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_most_similar(get_vector(\"sushi\") - get_vector(\"Japan\") + get_vector(\"France\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_most_similar(get_vector(\"Merkel\") - get_vector(\"Germany\") + get_vector(\"Canada\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "- Library for embedding exploration: https://github.com/koaning/whatlies/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Vlerick-MAI-NLP-demo.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
